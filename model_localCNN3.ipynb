{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0067e010",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb6414",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a703e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"whole Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d502f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodule_name</th>\n",
       "      <th>nodule_category</th>\n",
       "      <th>calcification</th>\n",
       "      <th>internal_structure</th>\n",
       "      <th>lobulation</th>\n",
       "      <th>margin</th>\n",
       "      <th>nodule_type</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>texture</th>\n",
       "      <th>global_seed</th>\n",
       "      <th>slice_thickness</th>\n",
       "      <th>slices_present</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small Cell Lung Cancer (SCLC)</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Soft Tissue</td>\n",
       "      <td>Nn-Mk</td>\n",
       "      <td>P-Sharp</td>\n",
       "      <td>m4</td>\n",
       "      <td>Lin-Ov</td>\n",
       "      <td>NS-PS</td>\n",
       "      <td>3388.5178</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[53, 54, 55, 56, 57]</td>\n",
       "      <td>../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Soft Tissue</td>\n",
       "      <td>N-Marked</td>\n",
       "      <td>Poo-Sh</td>\n",
       "      <td>m7</td>\n",
       "      <td>Ovoid</td>\n",
       "      <td>Part Solid/Mixed</td>\n",
       "      <td>9335.7762</td>\n",
       "      <td>2.00</td>\n",
       "      <td>[70, 71, 72, 73, 74, 75]</td>\n",
       "      <td>../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bronchioloalveolar Hyperplasia</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Soft Tissue</td>\n",
       "      <td>Nn-Mk</td>\n",
       "      <td>Poorly</td>\n",
       "      <td>b6</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NS-PS</td>\n",
       "      <td>9151.7012</td>\n",
       "      <td>2.50</td>\n",
       "      <td>[26, 27, 28]</td>\n",
       "      <td>../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carcinoid Tumors</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Non-Central</td>\n",
       "      <td>Soft Tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P-Sharp</td>\n",
       "      <td>m5</td>\n",
       "      <td>Ov-Ro</td>\n",
       "      <td>Solid</td>\n",
       "      <td>201.8990</td>\n",
       "      <td>2.50</td>\n",
       "      <td>[51, 52, 53]</td>\n",
       "      <td>../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intrapulmonary Lymph Nodes</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Soft Tissue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sharp</td>\n",
       "      <td>b7</td>\n",
       "      <td>Ovoid</td>\n",
       "      <td>Solid</td>\n",
       "      <td>8747.3172</td>\n",
       "      <td>1.25</td>\n",
       "      <td>[23, 24, 25, 26, 27]</td>\n",
       "      <td>../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      nodule_name nodule_category calcification  \\\n",
       "0   Small Cell Lung Cancer (SCLC)       Malignant        Absent   \n",
       "1                        Lymphoma       Malignant        Absent   \n",
       "2  Bronchioloalveolar Hyperplasia          Benign        Absent   \n",
       "3                Carcinoid Tumors       Malignant   Non-Central   \n",
       "4      Intrapulmonary Lymph Nodes          Benign        Absent   \n",
       "\n",
       "  internal_structure lobulation   margin nodule_type sphericity  \\\n",
       "0        Soft Tissue      Nn-Mk  P-Sharp          m4     Lin-Ov   \n",
       "1        Soft Tissue   N-Marked   Poo-Sh          m7      Ovoid   \n",
       "2        Soft Tissue      Nn-Mk   Poorly          b6     Linear   \n",
       "3        Soft Tissue        NaN  P-Sharp          m5      Ov-Ro   \n",
       "4        Soft Tissue        NaN    Sharp          b7      Ovoid   \n",
       "\n",
       "            texture  global_seed  slice_thickness            slices_present  \\\n",
       "0             NS-PS    3388.5178             2.00      [53, 54, 55, 56, 57]   \n",
       "1  Part Solid/Mixed    9335.7762             2.00  [70, 71, 72, 73, 74, 75]   \n",
       "2             NS-PS    9151.7012             2.50              [26, 27, 28]   \n",
       "3             Solid     201.8990             2.50              [51, 52, 53]   \n",
       "4             Solid    8747.3172             1.25      [23, 24, 25, 26, 27]   \n",
       "\n",
       "                                           file_path  \n",
       "0  ../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...  \n",
       "1  ../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...  \n",
       "2  ../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...  \n",
       "3  ../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...  \n",
       "4  ../20241221_074106\\20241221_074106\\LIDC-IDRI\\L...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a792c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773f8ff",
   "metadata": {},
   "source": [
    "### Remove 34 nodules with missing annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07990fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodule_name            object\n",
      "nodule_category        object\n",
      "calcification          object\n",
      "internal_structure     object\n",
      "lobulation             object\n",
      "margin                 object\n",
      "nodule_type            object\n",
      "sphericity             object\n",
      "texture                object\n",
      "global_seed           float64\n",
      "slice_thickness       float64\n",
      "slices_present         object\n",
      "file_path              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2d11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df[\"slices_present\"] = df[\"slices_present\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f41abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 slices: 34 nodules\n",
      "1 slices: 18 nodules\n",
      "2 slices: 239 nodules\n",
      "3 slices: 376 nodules\n",
      "4 slices: 196 nodules\n",
      "5 slices: 163 nodules\n",
      "6 slices: 142 nodules\n",
      "7 slices: 123 nodules\n",
      "8 slices: 88 nodules\n",
      "9 slices: 50 nodules\n",
      "10 slices: 15 nodules\n",
      "11 slices: 16 nodules\n",
      "12 slices: 6 nodules\n",
      "13 slices: 12 nodules\n",
      "14 slices: 7 nodules\n",
      "18 slices: 1 nodules\n",
      "19 slices: 1 nodules\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "length_counts = Counter(len(x) for x in df[\"slices_present\"])\n",
    "for k in sorted(length_counts):\n",
    "    print(f\"{k} slices: {length_counts[k]} nodules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52216b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['slices_present'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35def17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((df['slices_present'].apply(len) == 0).sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8146fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c976f",
   "metadata": {},
   "source": [
    "### Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d450dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['nodule_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2a84b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Active Infection': 0, 'Adenocarcinoma': 1, 'Adenoid Cystic Carcinoma': 2, 'Bronchioloalveolar Hyperplasia': 3, 'Carcinoid Tumors': 4, 'Granuloma': 5, 'Hamartoma': 6, 'Intrapulmonary Lymph Nodes': 7, 'Large Cell (Undifferentiated) Carcinoma': 8, 'Lymphoma': 9, 'Metastatic Tumors': 10, 'Sarcoidosis': 11, 'Sarcomatoid Carcinoma': 12, 'Small Cell Lung Cancer (SCLC)': 13, 'Squamous Cell Carcinoma': 14}\n"
     ]
    }
   ],
   "source": [
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca20b2",
   "metadata": {},
   "source": [
    "NOTE: Long covid is not part of this study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c49024",
   "metadata": {},
   "source": [
    "# 2. Volume input preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b8ee6",
   "metadata": {},
   "source": [
    "For each sample:\n",
    "\n",
    "- volume_local: cropped region centered around nodule (based on segmentation)\n",
    "\n",
    "- volume_context: full slice (resized to something like 256×256), no crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f3606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse annotaions for bounding box\n",
    "\n",
    "import json\n",
    "\n",
    "def load_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    annotations = data.get(\"annotation\", [])\n",
    "    return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad2fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodule centroid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def polygon_centroid(norm_polygon, img_shape):\n",
    "    h, w = img_shape\n",
    "    x_coords = norm_polygon[::2]\n",
    "    y_coords = norm_polygon[1::2]\n",
    "    \n",
    "    # Convert to pixel space\n",
    "    x_pixels = [x * w for x in x_coords]\n",
    "    y_pixels = [y * h for y in y_coords]\n",
    "\n",
    "    x_center = int(np.mean(x_pixels))\n",
    "    y_center = int(np.mean(y_pixels))\n",
    "\n",
    "    return x_center, y_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549fd3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local crop and global context\n",
    "\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "def process_slice_local_context(dcm_path, segmentation, local_size=(64, 64), context_size=(256, 256)):\n",
    "    dcm = pydicom.dcmread(dcm_path)\n",
    "    img = dcm.pixel_array\n",
    "    h, w = img.shape\n",
    "\n",
    "    # Normalize pixel values\n",
    "    img = img.astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-5)\n",
    "\n",
    "    x_center, y_center = polygon_centroid(segmentation, (h, w))\n",
    "\n",
    "    # Crop around the center for local view\n",
    "    half_h, half_w = local_size[0] // 2, local_size[1] // 2\n",
    "    y1 = max(y_center - half_h, 0)\n",
    "    y2 = min(y_center + half_h, h)\n",
    "    x1 = max(x_center - half_w, 0)\n",
    "    x2 = min(x_center + half_w, w)\n",
    "    cropped_local = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Pad if needed\n",
    "    cropped_local = cv2.resize(cropped_local, local_size)\n",
    "\n",
    "    # Resize whole slice for context\n",
    "    resized_context = cv2.resize(img, context_size)\n",
    "\n",
    "    return cropped_local, resized_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b73f2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def remove_leading_duplicate_folder(path):\n",
    "    \"\"\"\n",
    "    Removes the first repeated folder name at the beginning of a path.\n",
    "    E.g., '../X\\\\X\\\\...' → 'X\\\\...'\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^(?:\\.\\.[\\\\/])?([^\\\\/]+)[\\\\/]\\1[\\\\/](.+)\", path)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}\\\\{match.group(2)}\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05750dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_path'] = df['file_path'].apply(remove_leading_duplicate_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f87e378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with 1 data sample\n",
    "\n",
    "json_path = df.iloc[0]['file_path'] \n",
    "\n",
    "\n",
    "annotations = load_annotations(json_path)\n",
    "\n",
    "local_slices = []\n",
    "context_slices = []\n",
    "\n",
    "for slice_dict in annotations:\n",
    "    for slice_idx, data in slice_dict.items():\n",
    "        dcm_filename = os.path.basename(data[\"dicomFile\"])\n",
    "        dcm_dir = os.path.dirname(json_path)\n",
    "        dcm_path = os.path.join(dcm_dir, dcm_filename)\n",
    "        segmentation = data[\"segmentation\"][0]  \n",
    "        local, context = process_slice_local_context(\n",
    "            dcm_path, segmentation,\n",
    "            local_size=(64, 64),\n",
    "            context_size=(256, 256)\n",
    "        )\n",
    "        local_slices.append(local)\n",
    "        context_slices.append(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a34863e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads or crops a list of 2D slices to a fixed 3D volume.\n",
    "\n",
    "def pad_or_crop_volume(slices, target_depth, shape):\n",
    "    D = len(slices)\n",
    "    h, w = shape\n",
    "\n",
    "    if D == 0:\n",
    "        return np.zeros((1, target_depth, h, w), dtype=np.float32)\n",
    "\n",
    "    volume = np.stack(slices, axis=0)\n",
    "\n",
    "    if D < target_depth:\n",
    "        pad_before = (target_depth - D) // 2\n",
    "        pad_after = target_depth - D - pad_before\n",
    "        volume = np.pad(volume, ((pad_before, pad_after), (0, 0), (0, 0)), mode='constant')\n",
    "    elif D > target_depth:\n",
    "        start = (D - target_depth) // 2\n",
    "        volume = volume[start:start+target_depth]\n",
    "\n",
    "    return volume[None, ...]  # Add channel dim: [1, D, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09e114b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume_local shape: (1, 5, 64, 64)\n",
      "volume_context shape: (1, 7, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "volume_local = pad_or_crop_volume(local_slices, target_depth=5, shape=(64, 64))\n",
    "volume_context = pad_or_crop_volume(context_slices, target_depth=7, shape=(256, 256))\n",
    "\n",
    "print(\"volume_local shape:\", volume_local.shape)\n",
    "print(\"volume_context shape:\", volume_context.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2938a19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:  73%|███████▎  | 1058/1453 [00:13<00:05, 77.28it/s]"
     ]
    }
   ],
   "source": [
    "# Applying to entire dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_locals = []\n",
    "all_contexts = []\n",
    "all_labels = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing samples\"):\n",
    "    try:\n",
    "        json_path = row['file_path']\n",
    "        label = row['label']\n",
    "        annotations = load_annotations(json_path)\n",
    "\n",
    "        local_slices = []\n",
    "        context_slices = []\n",
    "\n",
    "        for slice_dict in annotations:\n",
    "            for slice_idx, data in slice_dict.items():\n",
    "                \n",
    "                dcm_filename = os.path.basename(data[\"dicomFile\"])\n",
    "                dcm_dir = os.path.dirname(json_path)\n",
    "                dcm_path = os.path.join(dcm_dir, dcm_filename)\n",
    "\n",
    "                segmentation = data[\"segmentation\"][0]\n",
    "                local, context = process_slice_local_context(\n",
    "                    dcm_path, segmentation,\n",
    "                    local_size=(64, 64),\n",
    "                    context_size=(256, 256)\n",
    "                )\n",
    "                local_slices.append(local)\n",
    "                context_slices.append(context)\n",
    "\n",
    "        volume_local = pad_or_crop_volume(local_slices, target_depth=5, shape=(64, 64))\n",
    "        volume_context = pad_or_crop_volume(context_slices, target_depth=7, shape=(256, 256))\n",
    "\n",
    "        all_locals.append(volume_local)\n",
    "        all_contexts.append(volume_context)\n",
    "        all_labels.append(label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464b356",
   "metadata": {},
   "source": [
    "# 3. Radiomics preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83471195",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics_columns = [\n",
    "    \"calcification\", \"internal_structure\", \"lobulation\",\n",
    "    \"margin\", \"sphericity\", \"texture\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics_df = df[radiomics_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0eb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics_encoded = pd.get_dummies(radiomics_df, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Radiomics vector shape:\", radiomics_encoded.shape)\n",
    "radiomics_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_radiomics = radiomics_encoded.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_radiomics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d7f601",
   "metadata": {},
   "source": [
    "# 4. Create Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleFusionDataset(Dataset):\n",
    "    def __init__(self, all_locals, all_contexts, X_radiomics, labels_df):\n",
    "        self.all_locals = all_locals\n",
    "        self.all_contexts = all_contexts\n",
    "        self.radiomics = X_radiomics\n",
    "        self.labels = labels_df[\"label\"].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            \"volume_local\": torch.tensor(self.all_locals[idx], dtype=torch.float32),\n",
    "            \"volume_context\": torch.tensor(self.all_contexts[idx], dtype=torch.float32),\n",
    "            \"radiomics\": torch.tensor(self.radiomics[idx], dtype=torch.float32),\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        }\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cdef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TripleFusionDataset(\n",
    "    all_locals=all_locals,\n",
    "    all_contexts=all_contexts,\n",
    "    X_radiomics=X_radiomics,\n",
    "    labels_df=df  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3cc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e075d",
   "metadata": {},
   "source": [
    "# 5. Triple Fusion Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7cfffe",
   "metadata": {},
   "source": [
    "\n",
    "| Branch           | Input Shape           | Type     |\n",
    "|------------------|------------------------|----------|\n",
    "| `volume_local`   | `[B, 1, 5, 64, 64]`     | 3D CNN   |\n",
    "| `volume_context` | `[B, 1, 7, 256, 256]`   | 3D CNN   |\n",
    "| `radiomics`      | `[B, 25]`               | MLP      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd727c",
   "metadata": {},
   "source": [
    "### Local Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),  # (5,64,64) → (2,32,32)\n",
    "\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d((1, 1, 1))  # output: [B, 32, 1, 1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x.view(x.size(0), -1)  # flatten to [B, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f05780",
   "metadata": {},
   "source": [
    "### Context Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992609b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),  # (7,256,256) → (3,128,128)\n",
    "\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d((1, 1, 1))  # output: [B, 32, 1, 1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x.view(x.size(0), -1)  # [B, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f264e75",
   "metadata": {},
   "source": [
    "### Radiomics Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadiomicsBranch(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62d431",
   "metadata": {},
   "source": [
    "### Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleFusionModel(nn.Module):\n",
    "    def __init__(self, num_classes, radiomics_dim=25):\n",
    "        super().__init__()\n",
    "        self.local_branch = LocalBranch()\n",
    "        self.context_branch = ContextBranch()\n",
    "        self.radiomics_branch = RadiomicsBranch(radiomics_dim)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 + 32 + 64, 64),  # fuse outputs\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, volume_local, volume_context, radiomics):\n",
    "        local_feat = self.local_branch(volume_local)\n",
    "        context_feat = self.context_branch(volume_context)\n",
    "        radio_feat = self.radiomics_branch(radiomics)\n",
    "\n",
    "        fused = torch.cat([local_feat, context_feat, radio_feat], dim=1)\n",
    "        out = self.classifier(fused)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794896c",
   "metadata": {},
   "source": [
    "# 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_classes = len(df[\"label\"].unique())\n",
    "model = TripleFusionModel(num_classes=num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62408063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501115dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in pbar:\n",
    "        start_time = time.time()\n",
    "\n",
    "        vol_local = batch[\"volume_local\"].to(device)\n",
    "        vol_context = batch[\"volume_context\"].to(device)\n",
    "        radiomics = batch[\"radiomics\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(vol_local, vol_context, radiomics)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = compute_accuracy(outputs, labels)\n",
    "        batch_time = time.time() - start_time\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"acc\": f\"{acc:.4f}\",\n",
    "            \"time\": f\"{batch_time:.2f}s\"\n",
    "        })\n",
    "\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb97a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"Validation\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            vol_local = batch[\"volume_local\"].to(device)\n",
    "            vol_context = batch[\"volume_context\"].to(device)\n",
    "            radiomics = batch[\"radiomics\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(vol_local, vol_context, radiomics)\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = compute_accuracy(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\": f\"{acc:.4f}\"\n",
    "            })\n",
    "\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef73bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Train-Validation Split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38777c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35272464",
   "metadata": {},
   "source": [
    "# 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40803edf",
   "metadata": {},
   "source": [
    "NOTE: I forgot to do a test dataset split so I'm currently gonna get a random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            vol_local = batch[\"volume_local\"].to(device)\n",
    "            vol_context = batch[\"volume_context\"].to(device)\n",
    "            radiomics = batch[\"radiomics\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(vol_local, vol_context, radiomics)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, dataloader, device, class_names):\n",
    "    y_pred, y_true = predict(model, dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477fb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torch.utils.data.Subset(dataset, range(int(0.85 * len(dataset)), len(dataset)))\n",
    "test_loader = DataLoader(test_set, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(le.classes_)\n",
    "evaluate_model(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b724455",
   "metadata": {},
   "source": [
    "# 8. Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ab5b3",
   "metadata": {},
   "source": [
    "### Grad-Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04064cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model.local_branch.conv[4]  # the second Conv3D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = GradCAM(model=model.local_branch, target_layers=[target_layer])\n",
    "\n",
    "batch = next(iter(test_loader))  # one batch\n",
    "input_tensor = batch[\"volume_local\"][0].unsqueeze(0).to(device)  # [1, 1, D, H, W]\n",
    "target_category = batch[\"label\"][0].item()\n",
    "\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(target_category)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the heatmap \n",
    "\n",
    "input_volume = batch[\"volume_local\"][0].squeeze(0).cpu().numpy() \n",
    "\n",
    "def normalize(x):\n",
    "    x = x - x.min()\n",
    "    x = x / (x.max() + 1e-5)\n",
    "    return x\n",
    "\n",
    "volume = batch[\"volume_local\"][0].squeeze(0).cpu().numpy()      \n",
    "grayscale = grayscale_cam[0]                                    \n",
    "\n",
    "# Take the middle slice\n",
    "mid = volume.shape[0] // 2\n",
    "slice_img = normalize(volume[mid])\n",
    "cam_slice = normalize(grayscale[mid])\n",
    "\n",
    "if cam_slice.shape != slice_img.shape:\n",
    "    cam_slice = cv2.resize(cam_slice, slice_img.shape[::-1])\n",
    "\n",
    "# Convert CAM to heatmap\n",
    "cam_uint8 = np.ascontiguousarray((cam_slice * 255).astype(np.uint8))\n",
    "heatmap = cv2.applyColorMap(cam_uint8, cv2.COLORMAP_JET)\n",
    "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "# Prepare grayscale CT image\n",
    "ct_rgb = np.stack([slice_img] * 3, axis=-1)\n",
    "\n",
    "overlay = 0.5 * ct_rgb + 0.5 * heatmap\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Grad-CAM Overlay (Middle Slice)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef3a23",
   "metadata": {},
   "source": [
    "# 9. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68631414",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"triple_fusion_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung_nodule_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
