# -*- coding: utf-8 -*-
"""NoduleReconstruction_v0_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12cHV9WjM2xNn5H-PqQnLw-Bpfumj_STI
"""
import matplotlib.pyplot as plt

from ipywidgets import interact
import cv2
import numpy as np
import pydicom
import json
import SimpleITK as stk
import os
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import matplotlib.pyplot as plt
from skimage import measure


class Nodule_Reconstruction:
  def __init__(self,
               dcom_path:str, # Path of .dcm sequence (e.g., 1-0067.dcm, 1-0068.dcm ... 1-00nn.dcm)
               json_dcom_path:str, # Path of .json file (e.g., segmentation_00036.json)
               level_of_detail:int = None): # On a scale from 1 to 10 the level of detail directly influences the verts and faces number
    self.dcom_path = dcom_path
    self.json_dcom_path = json_dcom_path

    # -------- Data readings ----------- # STARTS
    self.image, self.reader = self.load_dicom_Series(self.dcom_path)
    print("DICOM series successfully accessed at ... '{}'".format(self.dcom_path))
    # -------- Data readings ----------- # ENDS

  def load_dicom_Series(self, path:str)-> (stk.SimpleITK.Image,
                                   stk.SimpleITK.ImageSeriesReader):
        """
        load_dicom_Series used primarily to initialize the stk-related object that can
        be used to:
        * read DICOM file(s) and their annotations;
        \\ reader = stk.ImageSeriesReader() -> reade.GetGDCM...
        * attach to each CT a unique identifier and stack the counted CTs in a
        container (e.g., image)

        :path:str -> path to be accessed when reading the dicom file(s)
        :AUTOMATIC:bool -> by default False meaning that path it's going to be used.
                           Otherwise path needs to be specify when calling in load_dicom_Series
        :return: image object which has comes with nice reading-type functions (e.g. image.GetSize())
                 pass over the SimpleITK initialized object in the case any update is needed
        """
        # 1. Initialize the sitk class - ImageSeriesReade
        reader = stk.ImageSeriesReader()
        dicom_names = reader.GetGDCMSeriesFileNames(path)
        reader.SetFileNames(dicom_names)
        image = reader.Execute()

        return image, reader

        """
        Example:
        -------
        image, reader = load_dicom_Series('/content/')
        print(image)
        >>> Size: [512, 512, 103] ...
        print(type(reader),reader)
        >>> <class 'SimpleITK.SimpleITK.ImageSeriesReader'> itk::simple::ImageSeriesReader
        >>> FileNames:
        >>>   "/content/1-0001.dcm"
        >>>   "/content/1-0002.dcm"
        ------
        """

  def build_3d_Mask(self) -> np.ndarray:
    """
    build_3d_Mask it's employed only for extracting the `x, y and z`
    coordinates of a nodule defined by any dicom series at a given path

    :return: a 3D-matrix volume with shape (z, width, height)
    whose items contain (x,y) precise coordinates of the nodule
    """
    # 1. Open .json object in `r` mode:
    with open (self.json_dcom_path, 'r') as file:
      data = json.load(file) # 1.1. retrieving information (e.g., nodule's slices) out from loaded .json object

    # 2. Define the matrix-space based on `image sizes` and eventually `depth`
    num_annotated_slices = len(data['annotation'])
    volume = np.zeros((num_annotated_slices, self.image.GetSize()[1], self.image.GetSize()[0]), dtype=np.uint8)

    # 3. Itterating over `data` with `annotation` key in order to retrieve
    #(x, y) coordinates and z (e.g., deepness)\
    for z, slices in enumerate(data['annotation']): # 3.1. Extracting the number of slices (e.g., z axis)
      for slice in slices: # 3.2. Using the number indicating the exact slice to access the (x,y) coordinates
        coords = slices[slice]['segmentation'][0] # ...[0] to eliminate the nested lists

        # 4. Converting the list into a numpy array will help down the line
        coords = np.array(coords).reshape(-1,2) # ... to distribute coordinate on two separate columns
        coords[ :,0] *= self.image.GetSize()[0] # ... to independently multiply the x and y coordinate with the image maximum sizes
        coords[ :,1] *= self.image.GetSize()[1]

        # 5. Fill out the sparse-volume at each iteration:
        coords = coords.astype(np.int64) # 5.1. Change the coords type
        cv2.fillPoly(volume[z], [coords], color=1) # 5.2. Fill out the volume z

    print("3D Mask has been built")
    return volume

  def compute_max_nodule_extent(self, volume: np.ndarray) -> float:
      """
      Computes the maximum extent of the nodule in physical space.
      Evaluates XY, XZ, and YZ planar projections and returns the longest dimension.

      :param volume: 3D mask from build_3d_Mask
      :return: Maximum dimension (in mm assuming spacing=(1,1,1))
      """
      filled_voxels = np.argwhere(volume)  # Shape: (N_voxels, 3), order: z, y, x, filled_voxels is a non-sparse matrix

      if filled_voxels.size == 0:
          raise ValueError("Volume contains no voxels.")

      # Calculate axis-aligned bounding box (AABB) dimensions
      zmin, ymin, xmin = filled_voxels.min(axis=0)
      zmax, ymax, xmax = filled_voxels.max(axis=0)

      dx = xmax - xmin # Determining max length in plan dx,
      dy = ymax - ymin # Determining max length in plax dy,
      dz = zmax - zmin # Determining max length in play dz,

      # Return the maximum dimension
      max_extent = max(dx, dy, dz)

      print(f"Extent along X: {dx} mm")
      print(f"Extent along Y: {dy} mm")
      print(f"Extent along Z (slices): {dz} mm")
      print(f"Maximum extent (in any plane): {max_extent} mm")

      return max_extent


  def visualize_3d_Mask(self, volume):

    if np.max(volume) == 0:
      raise TypeError("Warning: Volume contains no segmented voxels.")

    # Vertices - a point where multiple lines meet
    # Faces - a flat triangle-surface which has exactly three veices
    # Normals - gradient direction which could be eiher positive or negative
    # Values - maximum gradient magnitude in the local region near each vertex

    # 1. Using marhcing cubes to extract verts, faces, normals and values
    verts, faces, normals, values = measure.marching_cubes(volume =volume,
                                                           level = None, # Uses the average of he min and max of volume
                                                           spacing=(1,1,1), # Space in-between pixels
                                                           gradient_direction='descent',
                                                           allow_degenerate=False,
                                                           method='lorensen')

    # 1.1. Information pertaining to Graphical Design elements
    # (e.g., Verts, Faces) and the size of the nodule in mm^2
    print("Verts:", verts.shape, "Faces:", faces.shape)

    # 2. Building the plot
    fig = plt.figure(figsize=(10, 10))

    ax = fig.add_subplot(111, projection='3d')
    verts_swapped = verts[:, [2, 1, 0]] # Inverting columns order to match M, N, P
    mesh = Poly3DCollection(verts_swapped[faces], alpha=0.65) # alpha ~ transparency

    mesh.set_edgecolor('k')
    ax.add_collection3d(mesh) # Add the 3D corp (e.g., mesh) to the 3D plan defined by `...add_subplot(111, projection='3d')`

    filled = np.argwhere(volume) # Considering only non-zero items in volume to enclose the graph to be able to see the nodule
    print(filled.shape)
    zmin, ymin, xmin = filled.min(axis=0)
    zmax, ymax, xmax = filled.max(axis=0)

    ax.set_xlim(xmin - 10, xmax + 10) # Tolerance +-10
    ax.set_ylim(ymin - 10, ymax + 10) # Tolerance +-10
    ax.set_zlim(zmin - 1, zmax + 1)  # Tolerance +- 1

    ax.set_xlabel("coord x")
    ax.set_ylabel("coord y")
    ax.set_zlabel("number of slices")
    plt.tight_layout()
    output_dir = os.path.join(os.path.dirname(__file__), "static")
    os.makedirs(output_dir, exist_ok=True)
    plt.savefig(os.path.join(output_dir, "recon.png"))
    #plt.show()
    pass