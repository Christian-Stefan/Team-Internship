{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Christian-Stefan/Team-Internship/blob/Chris/PipelinePreprocessing.ipynb",
      "authorship_tag": "ABX9TyPm0c87PPrvAmv8ZvY49gnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christian-Stefan/Team-Internship/blob/Chris/PipelinePreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "!pip install SimpleITK\n",
        "\n",
        "import SimpleITK as sitk\n",
        "import time as t\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json, glob, re, os, pydicom\n",
        "from skimage.draw import polygon\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.morphology import disk\n",
        "from scipy.ndimage import binary_fill_holes,label,binary_dilation,binary_erosion, binary_closing\n",
        "from ipywidgets import interact"
      ],
      "metadata": {
        "id": "FsCopolpA6qI",
        "outputId": "629a0698-ab47-4581-c7ae-9ee84390c0dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9OQ6zvIZZouT"
      },
      "outputs": [],
      "source": [
        "class Preprocessing:\n",
        "\n",
        "  def __init__(self,\n",
        "               Output_path:str,\n",
        "               Root_path:str,\n",
        "               Json_path:str = None):\n",
        "\n",
        "    self.Json_path = Json_path\n",
        "    self.Output_path = Output_path\n",
        "    self.Root_path = Root_path\n",
        "\n",
        "  def get_slice_and_coordnates_Paths(self,\n",
        "                                     root_path:str=None):\n",
        "      ct_collections = []\n",
        "\n",
        "      if root_path == None:\n",
        "        root_path = self.Root_path\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "      #print(\"Loading data from...{}\".format(root_path))\n",
        "      for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "          folder_name = os.path.basename(dirpath)\n",
        "          if \"-NA-\" in folder_name:\n",
        "              # print(\"Folder name:\", folder_name)\n",
        "\n",
        "              # Collect and sort full paths to .dcm files\n",
        "              dcm_files = sorted(\n",
        "                  [os.path.join(dirpath, f) for f in filenames if f.lower().endswith('.dcm')]\n",
        "              )\n",
        "\n",
        "              # Identify the .json file\n",
        "              json_files = [f for f in filenames if f.lower().endswith('.json')]\n",
        "              json_file = json_files[0] if json_files else None\n",
        "\n",
        "              if dcm_files and json_file:\n",
        "                  json_path = os.path.join(dirpath, json_file)\n",
        "\n",
        "                  # Load and parse JSON to extract annotations\n",
        "                  with open(json_path, 'r') as f:\n",
        "                      d = json.load(f)\n",
        "\n",
        "                  slice_coords = []\n",
        "                  for annotation in d.get(\"annotation\", []):\n",
        "                      slice_key = next(iter(annotation))\n",
        "                      coords = annotation[slice_key]['segmentation'][0]\n",
        "                      slice_coords.append(coords)\n",
        "\n",
        "                  # Full list of paths: DICOMs + JSON\n",
        "                  full_sequence = dcm_files + [json_path]\n",
        "\n",
        "                  # Append both: [paths, coordinates]\n",
        "                  ct_collections.append([full_sequence, slice_coords])\n",
        "\n",
        "      return ct_collections\n",
        "\n",
        "  def preprocess_Data(self,\n",
        "                data:list,\n",
        "                save_base_path:str = None,\n",
        "                plot:bool = True,\n",
        "                save:bool = False,\n",
        "                segment:bool = False,\n",
        "                output:bool = False):\n",
        "\n",
        "      '''\n",
        "          slice_paths: relative paths for each slice in a scan containing a nodule\n",
        "          slice_coords: coordinates of nodule for each slice in a scan\n",
        "          plot: want to plot the slices?\n",
        "          save: want to save the slices?\n",
        "          segment: want to output only nodule (so segmented) or the entire lungs?\n",
        "          output: want to return the output?\n",
        "\n",
        "      '''\n",
        "      # ---- Containers Definition ----- # Starts\n",
        "      slices_coords:list = [] # Container with nodule cordinates\n",
        "      slices_paths:list = [] # Container with nodule paths\n",
        "      slices_z:list = [] # Deepness of each nodule belonging to a given CT\n",
        "      slies_deepness:list = [] # Deepness of each CT\n",
        "      slices_deepness:list = [len(data[deep][0]) for deep in range(len(data))] # Deepness of each CT through list comprehension\n",
        "      processed_out:list = []\n",
        "      index_coords:int = 0\n",
        "      # ---- Containers Definition ----- # Ends\n",
        "\n",
        "      # 1. Extracting relaive paths and nodule coordinates\n",
        "      for file in data:\n",
        "        if 'segmentation' in str(file[:][0]): # Sorting out coordinates and identifying all the paths\n",
        "          json_file = file[:][0][(len(file[:][0])-1)] # 1.1 Selecting the very last element in the subdirectory which usually is .json\n",
        "          with open(json_file,'r' ) as file_json:\n",
        "            json_segmentation = json.load(file_json)\n",
        "            for z, slices in enumerate(json_segmentation['annotation']):# 3.1. Extracting the number of slices (e.g., z axis)\n",
        "              for slice in slices: # 3.2. Using the number indicating the exact slice to access the (x,y) coordinates\n",
        "                # 2. After slices of interest have been localized dcmread is possible\n",
        "                slices_coords.append([slices[slice]['segmentation'][0]]) # Appending Slices Coordinates\n",
        "                if len(str(slice)) == 2:\n",
        "                  expected_filename = f\"1-{int(slice):04d}.dcm\"\n",
        "                  for slice_path in file[:][0]:\n",
        "                    if expected_filename in slice_path:\n",
        "                      slices_paths.append(slice_path) # Appending Slice Paths\n",
        "            slices_z.append([z])\n",
        "        # -- Baseline 1 -> slice_paths, slices_coords\n",
        "      # 3. Parse .dicom dataset\n",
        "      for ct in range(len(data)):\n",
        "\n",
        "        processed_out_temporary:list = [] # Initialize a temporary container/chunk per CT\n",
        "\n",
        "        ct_overall_deepness = len(data[ct][0]) # Parse the slice sequence of all CTs\n",
        "        # print(\"Processing CT:{}, which has the deepness of {}\\n\".format(data[ct][0],\n",
        "        #                                                               ct_overall_deepness))\n",
        "        # 3.1. Read with .dcmread each slice\n",
        "        for slice_index in range(slices_z[ct][0]+1):\n",
        "          path = slices_paths[0]\n",
        "          dicom_data = pydicom.dcmread(path) # Reading slice by slice a given CT\n",
        "          IMAGE_RAW = dicom_data.pixel_array # Raw image\n",
        "          IMAGE_NOT_RAW = dicom_data.pixel_array.astype(np.float32) # Not-raw image\n",
        "\n",
        "          # 4. Segment lung\n",
        "          IMAGE_LUNG = self.segment_lungs(IMAGE_NOT_RAW)\n",
        "\n",
        "          if sum(sum(IMAGE_LUNG))>5000000:\n",
        "            IMAGE_LUNG = self.segment_lungs(IMAGE_NOT_RAW,\n",
        "                                            threshold_non_black = 200,\n",
        "                                            threshold_lung_mult = 0.4)\n",
        "          # 5. Segment nodule\n",
        "          if segment:\n",
        "            IMAGE_LUNG = self.segment_nodule(IMAGE_NOT_RAW,\n",
        "                                       IMAGE_LUNG,\n",
        "                                       slice=slices_coords[index_coords][0])\n",
        "            index_coords+=1 # Update nodule coordinate index\n",
        "\n",
        "          processed_out_temporary.append(IMAGE_LUNG)   # Adding processed slices in a temporary list-type chunk\n",
        "          slices_paths.pop(0) # Removing the slice path from slices paths\n",
        "\n",
        "        processed_out.append(processed_out_temporary) # Adding processed CTs in processed_out container\n",
        "\n",
        "      #print(f\"Number of CTs preprocessed: {len(processed_out)}\\n\")\n",
        "\n",
        "      if plot:\n",
        "        pass\n",
        "        # Displaying the preprocessed CT with the most slices\n",
        "        # Determining and Appending the deepness\n",
        "        # for group_index in range(len(slices_z)):\n",
        "        #   volume = np.stack(processed_out[group_index], axis=2)\n",
        "        #   volume_z_first = np.transpose(volume, (2, 0, 1))\n",
        "        #   self.explore_3D_array(volume_z_first)\n",
        "\n",
        "        # max_z_index = slices_z.index(max(slices_z)) # Identifying the CT's index with higest number of slices that contain nodule(s)\n",
        "        # len_z_on_index = len(processed_out[max_z_index]) # Determining the number of slices containing nodule(s)\n",
        "        # slices = processed_out[max_z_index]\n",
        "        # volume = np.stack(processed_out[max_z_index], axis=2)\n",
        "        # volume_z_first = np.transpose(volume, (2, 0, 1))\n",
        "        # self.explore_3D_array(volume_z_first)\n",
        "\n",
        "  def segment_lungs(self,\n",
        "                    image,\n",
        "                    threshold_non_black = 100,\n",
        "                    threshold_lung_mult = 1):\n",
        "    # Remove completely black background\n",
        "    non_black_mask = image > threshold_non_black  # Ignore pure black regions outside scan\n",
        "    scan_region = binary_fill_holes(non_black_mask)  # Fill holes in the scan area\n",
        "\n",
        "    # Apply thresholding **only inside the scan region**\n",
        "    thresh = threshold_otsu(image[scan_region])  # Compute threshold ignoring black border\n",
        "    lung_mask = (image < thresh*threshold_lung_mult) & scan_region  # Select dark regions **inside the scan**\n",
        "\n",
        "    # Morphological operations to clean up\n",
        "    lung_mask = binary_dilation(lung_mask, iterations=3) # add back in some of the area around the lungs\n",
        "    lung_mask = binary_fill_holes(lung_mask)  # Fill small holes, helps if nodule was close to lung wall\n",
        "\n",
        "    # keep the two largest regions (lungs)\n",
        "    labeled_mask, num_features = label(lung_mask)\n",
        "    unique, counts = np.unique(labeled_mask, return_counts=True)\n",
        "    sorted_labels = sorted(zip(unique[1:], counts[1:]), key=lambda x: -x[1])[:2]  # Top 2 largest\n",
        "    lung_mask = np.isin(labeled_mask, [s[0] for s in sorted_labels])  # Keep only lungs\n",
        "\n",
        "    lung_mask = binary_erosion(lung_mask, disk(4)) # remove lung wall\n",
        "\n",
        "    # final mask\n",
        "    lungs_only = np.zeros_like(image)\n",
        "    lungs_only[lung_mask] = image[lung_mask]\n",
        "\n",
        "    return lungs_only\n",
        "\n",
        "  def segment_nodule(self,\n",
        "                     image,\n",
        "                     lungs_only,\n",
        "                     slice):\n",
        "\n",
        "    height, width = image.shape\n",
        "\n",
        "    x_coords = slice[::2]\n",
        "    y_coords = slice[1::2]\n",
        "\n",
        "    x_coords_new = (np.array(x_coords) * width).astype(int)\n",
        "    y_coords_new = (np.array(y_coords) * height).astype(int)\n",
        "\n",
        "\n",
        "    mask = np.zeros_like(image, dtype=bool)\n",
        "\n",
        "    # Get polygon fill area\n",
        "    rr, cc = polygon(y_coords_new, x_coords_new, mask.shape)\n",
        "    mask[rr, cc] = True  # Fill the polygon\n",
        "\n",
        "    # Fill any holes inside the polygon\n",
        "    mask = binary_fill_holes(mask)\n",
        "\n",
        "    # Expand mask by 4 pixels\n",
        "    mask = binary_dilation(mask, iterations=3)\n",
        "\n",
        "\n",
        "    # Create the masked image\n",
        "    masked_image = np.zeros_like(lungs_only)\n",
        "    masked_image[mask] = lungs_only[mask]  # Retain original pixels inside the boundary\n",
        "\n",
        "    min_x = min(x_coords_new)\n",
        "    max_x = max(x_coords_new)\n",
        "    min_y = min(y_coords_new)\n",
        "    max_y = max(y_coords_new)\n",
        "    padding = 5  # You can adjust this value as needed\n",
        "\n",
        "    # Adjust the bounding box coordinates with padding\n",
        "    min_x -= padding\n",
        "    max_x += padding\n",
        "    min_y -= padding\n",
        "    max_y += padding\n",
        "\n",
        "    cropped_image = masked_image[min_y:max_y, min_x:max_x]\n",
        "\n",
        "    cropped_image = self.pad_to_size(cropped_image,64)\n",
        "    before_image = cropped_image.copy()\n",
        "    med = np.median(cropped_image[cropped_image != 0])\n",
        "    mask_fill = (cropped_image >= (med * 0.95)).astype(int)\n",
        "    mask_fill = binary_closing(mask_fill, structure=np.ones((3, 3)))\n",
        "\n",
        "    cropped_image_out = np.zeros_like(cropped_image)\n",
        "    cropped_image_out[mask_fill.astype(bool)] = before_image[mask_fill.astype(bool)]\n",
        "\n",
        "    return cropped_image_out\n",
        "\n",
        "  def pad_to_size(self,\n",
        "                  image,\n",
        "                  size):\n",
        "    height, width = image.shape\n",
        "\n",
        "    # Calculate padding amounts\n",
        "    pad_top = (size - height) // 2 if (size - height) // 2 >=0 else 0\n",
        "    pad_bottom = size - height - pad_top if size - height - pad_top >=0 else 0\n",
        "    pad_left = (size - width) // 2 if (size - width) // 2 >=0 else 0\n",
        "    pad_right = size - width - pad_left if size - width - pad_left >=0 else 0\n",
        "\n",
        "\n",
        "\n",
        "    # Apply padding (black pixels = 0)\n",
        "    padded_image = np.pad(image, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
        "\n",
        "    return padded_image\n",
        "\n",
        "\n",
        "  def explore_3D_array(self,\n",
        "                       arr: np.ndarray,\n",
        "                       cmap: str = 'gray'):\n",
        "    \"\"\"\n",
        "    Given a 3D array with shape (Z,X,Y) This function will create an interactive\n",
        "    widget to check out all the 2D arrays with shape (X,Y) inside the 3D array.\n",
        "    The purpose of this function to visual inspect the 2D arrays in the image.\n",
        "\n",
        "    Args:\n",
        "      arr : 3D array with shape (Z,X,Y) that represents the volume of a MRI image\n",
        "      cmap : Which color map use to plot the slices in matplotlib.pyplot\n",
        "    \"\"\"\n",
        "\n",
        "    def fn(SLICE):\n",
        "      plt.figure(figsize=(12,12))\n",
        "      plt.imshow(arr[SLICE, :, :], cmap=cmap)\n",
        "      plt.show()\n",
        "\n",
        "    interact(fn, SLICE=(0, arr.shape[0]-1))\n",
        "\n",
        "\n",
        "  def explore_3D_array_comparison(arr_before: np.ndarray, arr_after: np.ndarray, cmap: str = 'gray'):\n",
        "    \"\"\"\n",
        "    Given two 3D arrays with shape (Z,X,Y) This function will create an interactive\n",
        "    widget to check out all the 2D arrays with shape (X,Y) inside the 3D arrays.\n",
        "    The purpose of this function to visual compare the 2D arrays after some transformation.\n",
        "\n",
        "    Args:\n",
        "      arr_before : 3D array with shape (Z,X,Y) that represents the volume of a MRI image, before any transform\n",
        "      arr_after : 3D array with shape (Z,X,Y) that represents the volume of a MRI image, after some transform\n",
        "      cmap : Which color map use to plot the slices in matplotlib.pyplot\n",
        "    \"\"\"\n",
        "\n",
        "    assert arr_after.shape == arr_before.shape\n",
        "\n",
        "    def fn(SLICE):\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(10,10))\n",
        "\n",
        "      ax1.set_title('Before', fontsize=15)\n",
        "      ax1.imshow(arr_before[SLICE, :, :], cmap=cmap)\n",
        "\n",
        "      ax2.set_title('After', fontsize=15)\n",
        "      ax2.imshow(arr_after[SLICE, :, :], cmap=cmap)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "    interact(fn, SLICE=(0, arr_before.shape[0]-1))\n",
        "\n",
        "  @staticmethod\n",
        "  def save_as_dicom(original_dicom, image_array, output_path):\n",
        "      # Create a new DICOM dataset based on the original\n",
        "      new_dicom = original_dicom.copy()\n",
        "\n",
        "      # Update pixel data with the new padded image\n",
        "      new_dicom.Rows, new_dicom.Columns = image_array.shape\n",
        "      new_dicom.PixelData = image_array.astype(np.uint16).tobytes()  # Convert to bytes\n",
        "\n",
        "      # Save as DICOM\n",
        "      new_dicom.save_as(output_path)\n",
        "      #print(f\"Saved: {output_path}\")\n",
        "\n",
        "\n",
        "Processing = Preprocessing(Output_path=\"/content/drive/MyDrive/TeamInternship/Ouput_Data\",\n",
        "                           Root_path=\"/content/drive/MyDrive/TeamInternship/Input_Data\")\n",
        "\n",
        "dcm_files = Processing.get_slice_and_coordnates_Paths()\n",
        "Processing.preprocess_Data(dcm_files)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NR4o4NK8nE4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}